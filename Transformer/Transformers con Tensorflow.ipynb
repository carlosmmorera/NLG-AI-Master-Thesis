{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c148af",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "Utilizamos un tokenizer preentrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c38b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf\n",
    "\n",
    "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
    "tf.keras.utils.get_file(\n",
    "    f\"{model_name}.zip\",\n",
    "    f\"http://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c6ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7010\n",
      "7765\n"
     ]
    }
   ],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)\n",
    "print(tokenizers.en.get_vocab_size().numpy())\n",
    "print(tokenizers.pt.get_vocab_size().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326a835",
   "metadata": {},
   "source": [
    "Ejemplo para tokenizar y decodificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45191510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[2, 3]]>\n",
      "tf.Tensor([[2 3 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int64)\n",
      "[2, 951, 37, 684, 1207, 1374, 1010, 518, 1423, 4, 864, 71, 2021, 4, 90, 27, 37, 684, 1207, 1374, 1010, 111, 269, 1227, 105, 271, 966, 1224, 117, 27, 4734, 1395, 587, 13, 1850, 587, 13, 676, 587, 151, 27, 71, 58, 3902, 4826, 2973, 77, 269, 13, 5022, 4312, 54, 15, 55, 15, 58, 15, 52, 15, 102, 4587, 1282, 100, 4092, 4, 10, 121, 296, 73, 1098, 11, 125, 79, 96, 4, 2159, 3735, 1724, 6185, 3129, 1058, 2626, 2050, 3107, 5432, 8, 47, 4096, 271, 601, 485, 3]\n",
      "[2, 951, 37, 684, 1207, 1374, 1010, 518, 1423, 4, 864, 71, 2021, 4, 90, 27, 37, 684, 1207, 1374, 1010, 111, 269, 1227, 105, 271, 966, 1224, 117, 27, 4734, 1395, 587, 13, 1850, 587, 13, 676, 587, 151, 27, 71, 58, 3902, 4826, 2973, 77, 269, 13, 5022, 4312, 54, 15, 55, 15, 58, 15, 52, 15, 102, 4587, 1282, 100, 4092, 4, 10, 121, 296, 73, 1098, 11, 125, 79, 96, 4, 2159, 3735, 1724, 6185, 3129, 1058, 2626, 2050, 3107, 5432, 8, 47, 4096, 271, 601, 485, 3]\n",
      "[2, 137, 9, 55, 90, 45, 1249, 15, 78, 94, 105, 4898, 76, 100, 4345, 10, 85, 103, 194, 45, 181, 73, 1601, 130, 71, 443, 1260, 72, 3340, 77, 147, 4634, 88, 11, 15, 3]\n",
      "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "example = \"Attention AB 1890 Group Members! SAVE THE DATE! What: AB 1890 Annual Retreat When: November 13th, 14th, 15th Where: The Villagio Inn, Napa R.S.V.P. attendance ASAP! (More information to follow) See you there! Delaney Hunter Legislative Director Smith & Kemtpon\"\n",
    "example2 = \"Here's what I sent. We can revise it as appropriate (for one thing I need to total up the dollars involved and fill in some blanks).\"\n",
    "encoded = tokenizers.en.tokenize([''])\n",
    "print(encoded)\n",
    "print(encoded.to_tensor(shape=[None, 10]))\n",
    "\n",
    "encoded = tokenizers.en.tokenize([example])\n",
    "for row in encoded.to_list():\n",
    "    print(row)\n",
    "\n",
    "encoded = tokenizers.en.tokenize(tf.constant([example, example2]))\n",
    "\n",
    "for row in encoded.to_list():\n",
    "    print(row)\n",
    "print(type(encoded))\n",
    "print(len(encoded.to_list()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1649ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention ab 1890 group members ! save the date ! what : ab 1890 annual retreat when : november 13th , 14th , 15th where : the villagio inn , napa r . s . v . p . attendance asap ! ( more information to follow ) see you there ! delaney hunter legislative director smith & kemtpon\n",
      "here ' s what i sent . we can revise it as appropriate ( for one thing i need to total up the dollars involved and fill in some blanks ) .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "for line in round_trip.numpy():\n",
    "    print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6b26d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'attention', b'a', b'##b', b'18', b'##9', b'##0', b'group', b'members', b'!', b'save', b'the', b'date', b'!', b'what', b':', b'a', b'##b', b'18', b'##9', b'##0', b'an', b'##n', b'##ual', b're', b'##t', b'##re', b'##at', b'when', b':', b'november', b'13', b'##th', b',', b'14', b'##th', b',', b'15', b'##th', b'where', b':', b'the', b'v', b'##ill', b'##ag', b'##io', b'in', b'##n', b',', b'na', b'##pa', b'r', b'.', b's', b'.', b'v', b'.', b'p', b'.', b'at', b'##tend', b'##ance', b'as', b'##ap', b'!', b'(', b'more', b'information', b'to', b'follow', b')', b'see', b'you', b'there', b'!', b'de', b'##lan', b'##ey', b'hunter', b'leg', b'##is', b'##la', b'##tive', b'director', b'smith', b'&', b'k', b'##em', b'##t', b'##p', b'##on', b'[END]'], [b'[START]', b'here', b\"'\", b's', b'what', b'i', b'sent', b'.', b'we', b'can', b're', b'##vise', b'it', b'as', b'appropriate', b'(', b'for', b'one', b'thing', b'i', b'need', b'to', b'total', b'up', b'the', b'dollars', b'involved', b'and', b'fill', b'in', b'some', b'blank', b'##s', b')', b'.', b'[END]']]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60e1cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 94), dtype=int64, numpy=\n",
       "array([[   2,  951,   37,  684, 1207, 1374, 1010,  518, 1423,    4,  864,\n",
       "          71, 2021,    4,   90,   27,   37,  684, 1207, 1374, 1010,  111,\n",
       "         269, 1227,  105,  271,  966, 1224,  117,   27, 4734, 1395,  587,\n",
       "          13, 1850,  587,   13,  676,  587,  151,   27,   71,   58, 3902,\n",
       "        4826, 2973,   77,  269,   13, 5022, 4312,   54,   15,   55,   15,\n",
       "          58,   15,   52,   15,  102, 4587, 1282,  100, 4092,    4,   10,\n",
       "         121,  296,   73, 1098,   11,  125,   79,   96,    4, 2159, 3735,\n",
       "        1724, 6185, 3129, 1058, 2626, 2050, 3107, 5432,    8,   47, 4096,\n",
       "         271,  601,  485,    3,    0,    0],\n",
       "       [   2,  137,    9,   55,   90,   45, 1249,   15,   78,   94,  105,\n",
       "        4898,   76,  100, 4345,   10,   85,  103,  194,   45,  181,   73,\n",
       "        1601,  130,   71,  443, 1260,   72, 3340,   77,  147, 4634,   88,\n",
       "          11,   15,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.to_tensor(shape=[None, 94])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46edbd",
   "metadata": {},
   "source": [
    "# Setup input pipeline\n",
    "Primero necesitaremos una función que tokenice los pares InIts y cuerpo del mensaje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae14967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "   array([[   2,   71,    3],\n",
       "          [   2, 2016,    3]], dtype=int64)>,\n",
       "   <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "   array([[  2, 144,   3],\n",
       "          [  2, 703,   3]], dtype=int64)>,\n",
       "   <tf.Tensor: shape=(4, 4), dtype=int64, numpy=\n",
       "   array([[   2,   71,    3,    0],\n",
       "          [   2, 1648,    3,    0],\n",
       "          [   2,   74,    3,    0],\n",
       "          [   2,  978, 2564,    3]], dtype=int64)>),\n",
       "  (<tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[ 2, 78,  3]], dtype=int64)>,\n",
       "   <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "   array([[  2, 153,   3],\n",
       "          [  2, 184,   3]], dtype=int64)>,\n",
       "   <tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n",
       "   array([[   2, 2158,  555,    3],\n",
       "          [   2, 2205,    3,    0]], dtype=int64)>)],\n",
       " <tf.Tensor: shape=(1, 24), dtype=int64, numpy=\n",
       " array([[   2,   78,  234,   97,  121, 2898,   15,   71, 2016,  144,  703,\n",
       "           71, 1648,   74,  978, 2564,   15,   78,  153,  184, 2158,  555,\n",
       "          930,    3]], dtype=int64)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LENGTH_SUBJECT = 20\n",
    "LENGTH_VERB = 15\n",
    "LENGTH_OBJECT = 10\n",
    "\n",
    "def tokenize_pairs(inits, message):\n",
    "    token_inits = []\n",
    "    for init in inits:\n",
    "        s = tokenizers.en.tokenize(init['Subject'])\n",
    "        # Convert from ragged to dense, padding with zeros.\n",
    "        s = s.to_tensor()\n",
    "\n",
    "        v = tokenizers.en.tokenize(init['Verb'])\n",
    "        # Convert from ragged to dense, padding with zeros.\n",
    "        v = v.to_tensor()\n",
    "\n",
    "        o = tokenizers.en.tokenize(init['Object'])\n",
    "        # Convert from ragged to dense, padding with zeros.\n",
    "        o = o.to_tensor()\n",
    "        token_inits.append((s,v,o))\n",
    "\n",
    "    msg = tokenizers.en.tokenize([message])\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    msg = msg.to_tensor()\n",
    "    return token_inits, msg\n",
    "\n",
    "tok = tokenize_pairs([{'Subject':['the', 'cat'], 'Verb':['has', 'taken'], 'Object' : ['the', 'ball', 'of', 'wool']},\n",
    "               {'Subject':['we'], 'Verb':['will', 'take'], 'Object' : ['corrective', 'actions']}],\n",
    "              'We should be more careful. The cat has taken the ball of wool. We will take corrective action')\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff5a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'corrective', b'actions'], dtype=object)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers.en.detokenize(tok[0][1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60423446",
   "metadata": {},
   "source": [
    "# Example set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a004961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_tokenize_pairs(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    pt = pt.to_tensor()\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    en = en.to_tensor()\n",
    "    return pt, en\n",
    "\n",
    "def bad_tokenizer(l):\n",
    "    return tokenizers.en.tokenize(l).to_tensor()\n",
    "\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def bad_make_batches(ds, b_size = 3):\n",
    "    return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .map(bad_tokenizer, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .batch(b_size)\n",
    "      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "def first_make_batch(ds):\n",
    "    return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(3))\n",
    "\n",
    "def make_batches(ds):\n",
    "    return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(ex_tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .prefetch(tf.data.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b1d55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "\n",
    "type(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99273cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>, 'validation': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>, 'test': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>}\n"
     ]
    }
   ],
   "source": [
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4449064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), ()), types: (tf.int32, tf.int32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([1, 3, 5]), array([-1, -3, -5])), (array([2, 4]), array([-2, -4]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(([1,2,3,4,5],[-1,-2,-3,-4,-5]))\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "dataset = dataset.shuffle(7, reshuffle_each_iteration=True)\n",
    "\n",
    "list(dataset.batch(3).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775151f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), ()), types: (tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string, tf.string)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([b's11', b's21', b's51'], dtype=object),\n",
       "  array([b'v11', b'v21', b'v51'], dtype=object),\n",
       "  array([b'o11', b'o21', b'o51'], dtype=object),\n",
       "  array([b's12', b's22', b's52'], dtype=object),\n",
       "  array([b'v12', b'v22', b'v52'], dtype=object),\n",
       "  array([b'o12', b'o22', b'o52'], dtype=object),\n",
       "  array([b's13', b's23', b's53'], dtype=object),\n",
       "  array([b'v13', b'v23', b'v53'], dtype=object),\n",
       "  array([b'o13', b'o23', b'o53'], dtype=object),\n",
       "  array([b's14', b's24', b's54'], dtype=object),\n",
       "  array([b'v14', b'v24', b'v54'], dtype=object),\n",
       "  array([b'o14', b'o24', b'o54'], dtype=object),\n",
       "  array([b's15', b's25', b's55'], dtype=object),\n",
       "  array([b'v15', b'v25', b'v55'], dtype=object),\n",
       "  array([b'o15', b'o25', b'o55'], dtype=object),\n",
       "  array([b's16', b's26', b's56'], dtype=object),\n",
       "  array([b'v16', b'v26', b'v56'], dtype=object),\n",
       "  array([b'o16', b'o26', b'o56'], dtype=object),\n",
       "  array([b't1', b't2', b't5'], dtype=object)),\n",
       " (array([b's41', b's31'], dtype=object),\n",
       "  array([b'v41', b'v31'], dtype=object),\n",
       "  array([b'o41', b'o31'], dtype=object),\n",
       "  array([b's42', b's32'], dtype=object),\n",
       "  array([b'v42', b'v32'], dtype=object),\n",
       "  array([b'o42', b'o32'], dtype=object),\n",
       "  array([b's43', b's33'], dtype=object),\n",
       "  array([b'v43', b'v33'], dtype=object),\n",
       "  array([b'o43', b'o33'], dtype=object),\n",
       "  array([b's44', b's34'], dtype=object),\n",
       "  array([b'v44', b'v34'], dtype=object),\n",
       "  array([b'o44', b'o34'], dtype=object),\n",
       "  array([b's45', b's35'], dtype=object),\n",
       "  array([b'v45', b'v35'], dtype=object),\n",
       "  array([b'o45', b'o35'], dtype=object),\n",
       "  array([b's46', b's36'], dtype=object),\n",
       "  array([b'v46', b'v36'], dtype=object),\n",
       "  array([b'o46', b'o36'], dtype=object),\n",
       "  array([b't4', b't3'], dtype=object))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_l(c, o='', n=5):\n",
    "    return [f'{c}{i + 1}' + o for i in range(n)]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((gen_l('s', '1'), gen_l('v', '1'), gen_l('o', '1'),\n",
    "                                              gen_l('s', '2'), gen_l('v', '2'), gen_l('o', '2'),\n",
    "                                              gen_l('s', '3'), gen_l('v', '3'), gen_l('o', '3'),\n",
    "                                              gen_l('s', '4'), gen_l('v', '4'), gen_l('o', '4'),\n",
    "                                              gen_l('s', '5'), gen_l('v', '5'), gen_l('o', '5'),\n",
    "                                              gen_l('s', '6'), gen_l('v', '6'), gen_l('o', '6'),gen_l('t')))\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "dataset = dataset.shuffle(7, reshuffle_each_iteration=True)\n",
    "\n",
    "list(dataset.batch(3).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b974cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (37,), types: tf.string>\n",
      "[array([b's a b b', b's b b b', b'v a b b', b'o a b b', b'o b b b',\n",
      "       b'o c b b', b's a b c', b's b b c', b'v a b c', b'o a b c',\n",
      "       b'o b b c', b'o c b c', b's a b d', b's b b d', b'v a b d',\n",
      "       b'o a b d', b'o b b d', b'o c b d', b's a b e', b's b b e',\n",
      "       b'v a b e', b'o a b e', b'o b b e', b'o c b e', b's a b f',\n",
      "       b's b b f', b'v a b f', b'o a b f', b'o b b f', b'o c b f',\n",
      "       b's a b g', b's b b g', b'v a b g', b'o a b g', b'o b b g',\n",
      "       b'o c b g', b't1'], dtype=object), array([b's a c b', b's b c b', b'v a c b', b'o a c b', b'o b c b',\n",
      "       b'o c c b', b's a c c', b's b c c', b'v a c c', b'o a c c',\n",
      "       b'o b c c', b'o c c c', b's a c d', b's b c d', b'v a c d',\n",
      "       b'o a c d', b'o b c d', b'o c c d', b's a c e', b's b c e',\n",
      "       b'v a c e', b'o a c e', b'o b c e', b'o c c e', b's a c f',\n",
      "       b's b c f', b'v a c f', b'o a c f', b'o b c f', b'o c c f',\n",
      "       b's a c g', b's b c g', b'v a c g', b'o a c g', b'o b c g',\n",
      "       b'o c c g', b't2'], dtype=object), array([b's a d b', b's b d b', b'v a d b', b'o a d b', b'o b d b',\n",
      "       b'o c d b', b's a d c', b's b d c', b'v a d c', b'o a d c',\n",
      "       b'o b d c', b'o c d c', b's a d d', b's b d d', b'v a d d',\n",
      "       b'o a d d', b'o b d d', b'o c d d', b's a d e', b's b d e',\n",
      "       b'v a d e', b'o a d e', b'o b d e', b'o c d e', b's a d f',\n",
      "       b's b d f', b'v a d f', b'o a d f', b'o b d f', b'o c d f',\n",
      "       b's a d g', b's b d g', b'v a d g', b'o a d g', b'o b d g',\n",
      "       b'o c d g', b't3'], dtype=object), array([b's a e b', b's b e b', b'v a e b', b'o a e b', b'o b e b',\n",
      "       b'o c e b', b's a e c', b's b e c', b'v a e c', b'o a e c',\n",
      "       b'o b e c', b'o c e c', b's a e d', b's b e d', b'v a e d',\n",
      "       b'o a e d', b'o b e d', b'o c e d', b's a e e', b's b e e',\n",
      "       b'v a e e', b'o a e e', b'o b e e', b'o c e e', b's a e f',\n",
      "       b's b e f', b'v a e f', b'o a e f', b'o b e f', b'o c e f',\n",
      "       b's a e g', b's b e g', b'v a e g', b'o a e g', b'o b e g',\n",
      "       b'o c e g', b't4'], dtype=object), array([b's a f b', b's b f b', b'v a f b', b'o a f b', b'o b f b',\n",
      "       b'o c f b', b's a f c', b's b f c', b'v a f c', b'o a f c',\n",
      "       b'o b f c', b'o c f c', b's a f d', b's b f d', b'v a f d',\n",
      "       b'o a f d', b'o b f d', b'o c f d', b's a f e', b's b f e',\n",
      "       b'v a f e', b'o a f e', b'o b f e', b'o c f e', b's a f f',\n",
      "       b's b f f', b'v a f f', b'o a f f', b'o b f f', b'o c f f',\n",
      "       b's a f g', b's b f g', b'v a f g', b'o a f g', b'o b f g',\n",
      "       b'o c f g', b't5'], dtype=object)]\n",
      "<BatchDataset shapes: (None, 37), types: tf.string>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[b's a b b', b's b b b', b'v a b b', b'o a b b', b'o b b b',\n",
       "         b'o c b b', b's a b c', b's b b c', b'v a b c', b'o a b c',\n",
       "         b'o b b c', b'o c b c', b's a b d', b's b b d', b'v a b d',\n",
       "         b'o a b d', b'o b b d', b'o c b d', b's a b e', b's b b e',\n",
       "         b'v a b e', b'o a b e', b'o b b e', b'o c b e', b's a b f',\n",
       "         b's b b f', b'v a b f', b'o a b f', b'o b b f', b'o c b f',\n",
       "         b's a b g', b's b b g', b'v a b g', b'o a b g', b'o b b g',\n",
       "         b'o c b g', b't1'],\n",
       "        [b's a f b', b's b f b', b'v a f b', b'o a f b', b'o b f b',\n",
       "         b'o c f b', b's a f c', b's b f c', b'v a f c', b'o a f c',\n",
       "         b'o b f c', b'o c f c', b's a f d', b's b f d', b'v a f d',\n",
       "         b'o a f d', b'o b f d', b'o c f d', b's a f e', b's b f e',\n",
       "         b'v a f e', b'o a f e', b'o b f e', b'o c f e', b's a f f',\n",
       "         b's b f f', b'v a f f', b'o a f f', b'o b f f', b'o c f f',\n",
       "         b's a f g', b's b f g', b'v a f g', b'o a f g', b'o b f g',\n",
       "         b'o c f g', b't5'],\n",
       "        [b's a e b', b's b e b', b'v a e b', b'o a e b', b'o b e b',\n",
       "         b'o c e b', b's a e c', b's b e c', b'v a e c', b'o a e c',\n",
       "         b'o b e c', b'o c e c', b's a e d', b's b e d', b'v a e d',\n",
       "         b'o a e d', b'o b e d', b'o c e d', b's a e e', b's b e e',\n",
       "         b'v a e e', b'o a e e', b'o b e e', b'o c e e', b's a e f',\n",
       "         b's b e f', b'v a e f', b'o a e f', b'o b e f', b'o c e f',\n",
       "         b's a e g', b's b e g', b'v a e g', b'o a e g', b'o b e g',\n",
       "         b'o c e g', b't4']], dtype=object),\n",
       " array([[b's a c b', b's b c b', b'v a c b', b'o a c b', b'o b c b',\n",
       "         b'o c c b', b's a c c', b's b c c', b'v a c c', b'o a c c',\n",
       "         b'o b c c', b'o c c c', b's a c d', b's b c d', b'v a c d',\n",
       "         b'o a c d', b'o b c d', b'o c c d', b's a c e', b's b c e',\n",
       "         b'v a c e', b'o a c e', b'o b c e', b'o c c e', b's a c f',\n",
       "         b's b c f', b'v a c f', b'o a c f', b'o b c f', b'o c c f',\n",
       "         b's a c g', b's b c g', b'v a c g', b'o a c g', b'o b c g',\n",
       "         b'o c c g', b't2'],\n",
       "        [b's a d b', b's b d b', b'v a d b', b'o a d b', b'o b d b',\n",
       "         b'o c d b', b's a d c', b's b d c', b'v a d c', b'o a d c',\n",
       "         b'o b d c', b'o c d c', b's a d d', b's b d d', b'v a d d',\n",
       "         b'o a d d', b'o b d d', b'o c d d', b's a d e', b's b d e',\n",
       "         b'v a d e', b'o a d e', b'o b d e', b'o c d e', b's a d f',\n",
       "         b's b d f', b'v a d f', b'o a d f', b'o b d f', b'o c d f',\n",
       "         b's a d g', b's b d g', b'v a d g', b'o a d g', b'o b d g',\n",
       "         b'o c d g', b't3']], dtype=object)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_row(i):\n",
    "    l = []\n",
    "    for j in range(1, 7):\n",
    "        for e, n in [('s', 2), ('v', 1), ('o', 3)]:\n",
    "            for k in range(n):\n",
    "                l.append(f\"{e} {['a', 'b', 'c'][k]} {chr(ord('a') + i)} {chr(ord('a') + j)}\")\n",
    "    l.append(f't{i}')\n",
    "    return l\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([gen_row(i+1) for i in range(5)])\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "dataset = dataset.shuffle(7, reshuffle_each_iteration=True)\n",
    "print(dataset.batch(3))\n",
    "list(dataset.batch(3).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a370636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (37,), types: tf.string>\n",
      "<PrefetchDataset shapes: (None, None, None), types: tf.int64>\n",
      "5\n",
      "[array([[[   2,   55,   37,   42,   38,    3],\n",
      "        [   2,   55,   38,   42,   38,    3],\n",
      "        [   2,   58,   37,   42,   38,    3],\n",
      "        [   2,   51,   37,   42,   38,    3],\n",
      "        [   2,   51,   38,   42,   38,    3],\n",
      "        [   2,   51,   39,   42,   38,    3],\n",
      "        [   2,   55,   37,   42,   39,    3],\n",
      "        [   2,   55,   38,   42,   39,    3],\n",
      "        [   2,   58,   37,   42,   39,    3],\n",
      "        [   2,   51,   37,   42,   39,    3],\n",
      "        [   2,   51,   38,   42,   39,    3],\n",
      "        [   2,   51,   39,   42,   39,    3],\n",
      "        [   2,   55,   37,   42,   40,    3],\n",
      "        [   2,   55,   38,   42,   40,    3],\n",
      "        [   2,   58,   37,   42,   40,    3],\n",
      "        [   2,   51,   37,   42,   40,    3],\n",
      "        [   2,   51,   38,   42,   40,    3],\n",
      "        [   2,   51,   39,   42,   40,    3],\n",
      "        [   2,   55,   37,   42,   41,    3],\n",
      "        [   2,   55,   38,   42,   41,    3],\n",
      "        [   2,   58,   37,   42,   41,    3],\n",
      "        [   2,   51,   37,   42,   41,    3],\n",
      "        [   2,   51,   38,   42,   41,    3],\n",
      "        [   2,   51,   39,   42,   41,    3],\n",
      "        [   2,   55,   37,   42,   42,    3],\n",
      "        [   2,   55,   38,   42,   42,    3],\n",
      "        [   2,   58,   37,   42,   42,    3],\n",
      "        [   2,   51,   37,   42,   42,    3],\n",
      "        [   2,   51,   38,   42,   42,    3],\n",
      "        [   2,   51,   39,   42,   42,    3],\n",
      "        [   2,   55,   37,   42,   43,    3],\n",
      "        [   2,   55,   38,   42,   43,    3],\n",
      "        [   2,   58,   37,   42,   43,    3],\n",
      "        [   2,   51,   37,   42,   43,    3],\n",
      "        [   2,   51,   38,   42,   43,    3],\n",
      "        [   2,   51,   39,   42,   43,    3],\n",
      "        [   2,   56, 1800,    3,    0,    0]]], dtype=int64), array([[[   2,   55,   37,   41,   38,    3],\n",
      "        [   2,   55,   38,   41,   38,    3],\n",
      "        [   2,   58,   37,   41,   38,    3],\n",
      "        [   2,   51,   37,   41,   38,    3],\n",
      "        [   2,   51,   38,   41,   38,    3],\n",
      "        [   2,   51,   39,   41,   38,    3],\n",
      "        [   2,   55,   37,   41,   39,    3],\n",
      "        [   2,   55,   38,   41,   39,    3],\n",
      "        [   2,   58,   37,   41,   39,    3],\n",
      "        [   2,   51,   37,   41,   39,    3],\n",
      "        [   2,   51,   38,   41,   39,    3],\n",
      "        [   2,   51,   39,   41,   39,    3],\n",
      "        [   2,   55,   37,   41,   40,    3],\n",
      "        [   2,   55,   38,   41,   40,    3],\n",
      "        [   2,   58,   37,   41,   40,    3],\n",
      "        [   2,   51,   37,   41,   40,    3],\n",
      "        [   2,   51,   38,   41,   40,    3],\n",
      "        [   2,   51,   39,   41,   40,    3],\n",
      "        [   2,   55,   37,   41,   41,    3],\n",
      "        [   2,   55,   38,   41,   41,    3],\n",
      "        [   2,   58,   37,   41,   41,    3],\n",
      "        [   2,   51,   37,   41,   41,    3],\n",
      "        [   2,   51,   38,   41,   41,    3],\n",
      "        [   2,   51,   39,   41,   41,    3],\n",
      "        [   2,   55,   37,   41,   42,    3],\n",
      "        [   2,   55,   38,   41,   42,    3],\n",
      "        [   2,   58,   37,   41,   42,    3],\n",
      "        [   2,   51,   37,   41,   42,    3],\n",
      "        [   2,   51,   38,   41,   42,    3],\n",
      "        [   2,   51,   39,   41,   42,    3],\n",
      "        [   2,   55,   37,   41,   43,    3],\n",
      "        [   2,   55,   38,   41,   43,    3],\n",
      "        [   2,   58,   37,   41,   43,    3],\n",
      "        [   2,   51,   37,   41,   43,    3],\n",
      "        [   2,   51,   38,   41,   43,    3],\n",
      "        [   2,   51,   39,   41,   43,    3],\n",
      "        [   2,   56, 1044,    3,    0,    0]]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([gen_row(i+1) for i in range(5)])\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "bad_batches = bad_make_batches(dataset, 1)\n",
    "print(bad_batches)\n",
    "l = list(bad_batches.as_numpy_iterator())\n",
    "print(len(l))\n",
    "print(l[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f426919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (37,), types: tf.string>\n",
      "<PrefetchDataset shapes: (None, None, None), types: tf.int64>\n",
      "2\n",
      "[array([[[   2,   55,   37,   38,   38,    3],\n",
      "        [   2,   55,   38,   38,   38,    3],\n",
      "        [   2,   58,   37,   38,   38,    3],\n",
      "        [   2,   51,   37,   38,   38,    3],\n",
      "        [   2,   51,   38,   38,   38,    3],\n",
      "        [   2,   51,   39,   38,   38,    3],\n",
      "        [   2,   55,   37,   38,   39,    3],\n",
      "        [   2,   55,   38,   38,   39,    3],\n",
      "        [   2,   58,   37,   38,   39,    3],\n",
      "        [   2,   51,   37,   38,   39,    3],\n",
      "        [   2,   51,   38,   38,   39,    3],\n",
      "        [   2,   51,   39,   38,   39,    3],\n",
      "        [   2,   55,   37,   38,   40,    3],\n",
      "        [   2,   55,   38,   38,   40,    3],\n",
      "        [   2,   58,   37,   38,   40,    3],\n",
      "        [   2,   51,   37,   38,   40,    3],\n",
      "        [   2,   51,   38,   38,   40,    3],\n",
      "        [   2,   51,   39,   38,   40,    3],\n",
      "        [   2,   55,   37,   38,   41,    3],\n",
      "        [   2,   55,   38,   38,   41,    3],\n",
      "        [   2,   58,   37,   38,   41,    3],\n",
      "        [   2,   51,   37,   38,   41,    3],\n",
      "        [   2,   51,   38,   38,   41,    3],\n",
      "        [   2,   51,   39,   38,   41,    3],\n",
      "        [   2,   55,   37,   38,   42,    3],\n",
      "        [   2,   55,   38,   38,   42,    3],\n",
      "        [   2,   58,   37,   38,   42,    3],\n",
      "        [   2,   51,   37,   38,   42,    3],\n",
      "        [   2,   51,   38,   38,   42,    3],\n",
      "        [   2,   51,   39,   38,   42,    3],\n",
      "        [   2,   55,   37,   38,   43,    3],\n",
      "        [   2,   55,   38,   38,   43,    3],\n",
      "        [   2,   58,   37,   38,   43,    3],\n",
      "        [   2,   51,   37,   38,   43,    3],\n",
      "        [   2,   51,   38,   38,   43,    3],\n",
      "        [   2,   51,   39,   38,   43,    3],\n",
      "        [   2,   56, 1205,    3,    0,    0]],\n",
      "\n",
      "       [[   2,   55,   37,   39,   38,    3],\n",
      "        [   2,   55,   38,   39,   38,    3],\n",
      "        [   2,   58,   37,   39,   38,    3],\n",
      "        [   2,   51,   37,   39,   38,    3],\n",
      "        [   2,   51,   38,   39,   38,    3],\n",
      "        [   2,   51,   39,   39,   38,    3],\n",
      "        [   2,   55,   37,   39,   39,    3],\n",
      "        [   2,   55,   38,   39,   39,    3],\n",
      "        [   2,   58,   37,   39,   39,    3],\n",
      "        [   2,   51,   37,   39,   39,    3],\n",
      "        [   2,   51,   38,   39,   39,    3],\n",
      "        [   2,   51,   39,   39,   39,    3],\n",
      "        [   2,   55,   37,   39,   40,    3],\n",
      "        [   2,   55,   38,   39,   40,    3],\n",
      "        [   2,   58,   37,   39,   40,    3],\n",
      "        [   2,   51,   37,   39,   40,    3],\n",
      "        [   2,   51,   38,   39,   40,    3],\n",
      "        [   2,   51,   39,   39,   40,    3],\n",
      "        [   2,   55,   37,   39,   41,    3],\n",
      "        [   2,   55,   38,   39,   41,    3],\n",
      "        [   2,   58,   37,   39,   41,    3],\n",
      "        [   2,   51,   37,   39,   41,    3],\n",
      "        [   2,   51,   38,   39,   41,    3],\n",
      "        [   2,   51,   39,   39,   41,    3],\n",
      "        [   2,   55,   37,   39,   42,    3],\n",
      "        [   2,   55,   38,   39,   42,    3],\n",
      "        [   2,   58,   37,   39,   42,    3],\n",
      "        [   2,   51,   37,   39,   42,    3],\n",
      "        [   2,   51,   38,   39,   42,    3],\n",
      "        [   2,   51,   39,   39,   42,    3],\n",
      "        [   2,   55,   37,   39,   43,    3],\n",
      "        [   2,   55,   38,   39,   43,    3],\n",
      "        [   2,   58,   37,   39,   43,    3],\n",
      "        [   2,   51,   37,   39,   43,    3],\n",
      "        [   2,   51,   38,   39,   43,    3],\n",
      "        [   2,   51,   39,   39,   43,    3],\n",
      "        [   2,   56, 1222,    3,    0,    0]],\n",
      "\n",
      "       [[   2,   55,   37,   41,   38,    3],\n",
      "        [   2,   55,   38,   41,   38,    3],\n",
      "        [   2,   58,   37,   41,   38,    3],\n",
      "        [   2,   51,   37,   41,   38,    3],\n",
      "        [   2,   51,   38,   41,   38,    3],\n",
      "        [   2,   51,   39,   41,   38,    3],\n",
      "        [   2,   55,   37,   41,   39,    3],\n",
      "        [   2,   55,   38,   41,   39,    3],\n",
      "        [   2,   58,   37,   41,   39,    3],\n",
      "        [   2,   51,   37,   41,   39,    3],\n",
      "        [   2,   51,   38,   41,   39,    3],\n",
      "        [   2,   51,   39,   41,   39,    3],\n",
      "        [   2,   55,   37,   41,   40,    3],\n",
      "        [   2,   55,   38,   41,   40,    3],\n",
      "        [   2,   58,   37,   41,   40,    3],\n",
      "        [   2,   51,   37,   41,   40,    3],\n",
      "        [   2,   51,   38,   41,   40,    3],\n",
      "        [   2,   51,   39,   41,   40,    3],\n",
      "        [   2,   55,   37,   41,   41,    3],\n",
      "        [   2,   55,   38,   41,   41,    3],\n",
      "        [   2,   58,   37,   41,   41,    3],\n",
      "        [   2,   51,   37,   41,   41,    3],\n",
      "        [   2,   51,   38,   41,   41,    3],\n",
      "        [   2,   51,   39,   41,   41,    3],\n",
      "        [   2,   55,   37,   41,   42,    3],\n",
      "        [   2,   55,   38,   41,   42,    3],\n",
      "        [   2,   58,   37,   41,   42,    3],\n",
      "        [   2,   51,   37,   41,   42,    3],\n",
      "        [   2,   51,   38,   41,   42,    3],\n",
      "        [   2,   51,   39,   41,   42,    3],\n",
      "        [   2,   55,   37,   41,   43,    3],\n",
      "        [   2,   55,   38,   41,   43,    3],\n",
      "        [   2,   58,   37,   41,   43,    3],\n",
      "        [   2,   51,   37,   41,   43,    3],\n",
      "        [   2,   51,   38,   41,   43,    3],\n",
      "        [   2,   51,   39,   41,   43,    3],\n",
      "        [   2,   56, 1044,    3,    0,    0]]], dtype=int64), array([[[   2,   55,   37,   40,   38,    3],\n",
      "        [   2,   55,   38,   40,   38,    3],\n",
      "        [   2,   58,   37,   40,   38,    3],\n",
      "        [   2,   51,   37,   40,   38,    3],\n",
      "        [   2,   51,   38,   40,   38,    3],\n",
      "        [   2,   51,   39,   40,   38,    3],\n",
      "        [   2,   55,   37,   40,   39,    3],\n",
      "        [   2,   55,   38,   40,   39,    3],\n",
      "        [   2,   58,   37,   40,   39,    3],\n",
      "        [   2,   51,   37,   40,   39,    3],\n",
      "        [   2,   51,   38,   40,   39,    3],\n",
      "        [   2,   51,   39,   40,   39,    3],\n",
      "        [   2,   55,   37,   40,   40,    3],\n",
      "        [   2,   55,   38,   40,   40,    3],\n",
      "        [   2,   58,   37,   40,   40,    3],\n",
      "        [   2,   51,   37,   40,   40,    3],\n",
      "        [   2,   51,   38,   40,   40,    3],\n",
      "        [   2,   51,   39,   40,   40,    3],\n",
      "        [   2,   55,   37,   40,   41,    3],\n",
      "        [   2,   55,   38,   40,   41,    3],\n",
      "        [   2,   58,   37,   40,   41,    3],\n",
      "        [   2,   51,   37,   40,   41,    3],\n",
      "        [   2,   51,   38,   40,   41,    3],\n",
      "        [   2,   51,   39,   40,   41,    3],\n",
      "        [   2,   55,   37,   40,   42,    3],\n",
      "        [   2,   55,   38,   40,   42,    3],\n",
      "        [   2,   58,   37,   40,   42,    3],\n",
      "        [   2,   51,   37,   40,   42,    3],\n",
      "        [   2,   51,   38,   40,   42,    3],\n",
      "        [   2,   51,   39,   40,   42,    3],\n",
      "        [   2,   55,   37,   40,   43,    3],\n",
      "        [   2,   55,   38,   40,   43,    3],\n",
      "        [   2,   58,   37,   40,   43,    3],\n",
      "        [   2,   51,   37,   40,   43,    3],\n",
      "        [   2,   51,   38,   40,   43,    3],\n",
      "        [   2,   51,   39,   40,   43,    3],\n",
      "        [   2,   56, 1223,    3,    0,    0]],\n",
      "\n",
      "       [[   2,   55,   37,   42,   38,    3],\n",
      "        [   2,   55,   38,   42,   38,    3],\n",
      "        [   2,   58,   37,   42,   38,    3],\n",
      "        [   2,   51,   37,   42,   38,    3],\n",
      "        [   2,   51,   38,   42,   38,    3],\n",
      "        [   2,   51,   39,   42,   38,    3],\n",
      "        [   2,   55,   37,   42,   39,    3],\n",
      "        [   2,   55,   38,   42,   39,    3],\n",
      "        [   2,   58,   37,   42,   39,    3],\n",
      "        [   2,   51,   37,   42,   39,    3],\n",
      "        [   2,   51,   38,   42,   39,    3],\n",
      "        [   2,   51,   39,   42,   39,    3],\n",
      "        [   2,   55,   37,   42,   40,    3],\n",
      "        [   2,   55,   38,   42,   40,    3],\n",
      "        [   2,   58,   37,   42,   40,    3],\n",
      "        [   2,   51,   37,   42,   40,    3],\n",
      "        [   2,   51,   38,   42,   40,    3],\n",
      "        [   2,   51,   39,   42,   40,    3],\n",
      "        [   2,   55,   37,   42,   41,    3],\n",
      "        [   2,   55,   38,   42,   41,    3],\n",
      "        [   2,   58,   37,   42,   41,    3],\n",
      "        [   2,   51,   37,   42,   41,    3],\n",
      "        [   2,   51,   38,   42,   41,    3],\n",
      "        [   2,   51,   39,   42,   41,    3],\n",
      "        [   2,   55,   37,   42,   42,    3],\n",
      "        [   2,   55,   38,   42,   42,    3],\n",
      "        [   2,   58,   37,   42,   42,    3],\n",
      "        [   2,   51,   37,   42,   42,    3],\n",
      "        [   2,   51,   38,   42,   42,    3],\n",
      "        [   2,   51,   39,   42,   42,    3],\n",
      "        [   2,   55,   37,   42,   43,    3],\n",
      "        [   2,   55,   38,   42,   43,    3],\n",
      "        [   2,   58,   37,   42,   43,    3],\n",
      "        [   2,   51,   37,   42,   43,    3],\n",
      "        [   2,   51,   38,   42,   43,    3],\n",
      "        [   2,   51,   39,   42,   43,    3],\n",
      "        [   2,   56, 1800,    3,    0,    0]]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([gen_row(i+1) for i in range(5)])\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "bad_batches = bad_make_batches(dataset)\n",
    "print(bad_batches)\n",
    "l = list(bad_batches.as_numpy_iterator())\n",
    "print(len(l))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b126dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (37,), types: tf.string>\n",
      "<PrefetchDataset shapes: (None, None), types: tf.int64>\n",
      "5\n",
      "[array([[   2,   55,   37,   42,   38,    3],\n",
      "       [   2,   55,   38,   42,   38,    3],\n",
      "       [   2,   58,   37,   42,   38,    3],\n",
      "       [   2,   51,   37,   42,   38,    3],\n",
      "       [   2,   51,   38,   42,   38,    3],\n",
      "       [   2,   51,   39,   42,   38,    3],\n",
      "       [   2,   55,   37,   42,   39,    3],\n",
      "       [   2,   55,   38,   42,   39,    3],\n",
      "       [   2,   58,   37,   42,   39,    3],\n",
      "       [   2,   51,   37,   42,   39,    3],\n",
      "       [   2,   51,   38,   42,   39,    3],\n",
      "       [   2,   51,   39,   42,   39,    3],\n",
      "       [   2,   55,   37,   42,   40,    3],\n",
      "       [   2,   55,   38,   42,   40,    3],\n",
      "       [   2,   58,   37,   42,   40,    3],\n",
      "       [   2,   51,   37,   42,   40,    3],\n",
      "       [   2,   51,   38,   42,   40,    3],\n",
      "       [   2,   51,   39,   42,   40,    3],\n",
      "       [   2,   55,   37,   42,   41,    3],\n",
      "       [   2,   55,   38,   42,   41,    3],\n",
      "       [   2,   58,   37,   42,   41,    3],\n",
      "       [   2,   51,   37,   42,   41,    3],\n",
      "       [   2,   51,   38,   42,   41,    3],\n",
      "       [   2,   51,   39,   42,   41,    3],\n",
      "       [   2,   55,   37,   42,   42,    3],\n",
      "       [   2,   55,   38,   42,   42,    3],\n",
      "       [   2,   58,   37,   42,   42,    3],\n",
      "       [   2,   51,   37,   42,   42,    3],\n",
      "       [   2,   51,   38,   42,   42,    3],\n",
      "       [   2,   51,   39,   42,   42,    3],\n",
      "       [   2,   55,   37,   42,   43,    3],\n",
      "       [   2,   55,   38,   42,   43,    3],\n",
      "       [   2,   58,   37,   42,   43,    3],\n",
      "       [   2,   51,   37,   42,   43,    3],\n",
      "       [   2,   51,   38,   42,   43,    3],\n",
      "       [   2,   51,   39,   42,   43,    3],\n",
      "       [   2,   56, 1800,    3,    0,    0]], dtype=int64), array([[   2,   55,   37,   39,   38,    3],\n",
      "       [   2,   55,   38,   39,   38,    3],\n",
      "       [   2,   58,   37,   39,   38,    3],\n",
      "       [   2,   51,   37,   39,   38,    3],\n",
      "       [   2,   51,   38,   39,   38,    3],\n",
      "       [   2,   51,   39,   39,   38,    3],\n",
      "       [   2,   55,   37,   39,   39,    3],\n",
      "       [   2,   55,   38,   39,   39,    3],\n",
      "       [   2,   58,   37,   39,   39,    3],\n",
      "       [   2,   51,   37,   39,   39,    3],\n",
      "       [   2,   51,   38,   39,   39,    3],\n",
      "       [   2,   51,   39,   39,   39,    3],\n",
      "       [   2,   55,   37,   39,   40,    3],\n",
      "       [   2,   55,   38,   39,   40,    3],\n",
      "       [   2,   58,   37,   39,   40,    3],\n",
      "       [   2,   51,   37,   39,   40,    3],\n",
      "       [   2,   51,   38,   39,   40,    3],\n",
      "       [   2,   51,   39,   39,   40,    3],\n",
      "       [   2,   55,   37,   39,   41,    3],\n",
      "       [   2,   55,   38,   39,   41,    3],\n",
      "       [   2,   58,   37,   39,   41,    3],\n",
      "       [   2,   51,   37,   39,   41,    3],\n",
      "       [   2,   51,   38,   39,   41,    3],\n",
      "       [   2,   51,   39,   39,   41,    3],\n",
      "       [   2,   55,   37,   39,   42,    3],\n",
      "       [   2,   55,   38,   39,   42,    3],\n",
      "       [   2,   58,   37,   39,   42,    3],\n",
      "       [   2,   51,   37,   39,   42,    3],\n",
      "       [   2,   51,   38,   39,   42,    3],\n",
      "       [   2,   51,   39,   39,   42,    3],\n",
      "       [   2,   55,   37,   39,   43,    3],\n",
      "       [   2,   55,   38,   39,   43,    3],\n",
      "       [   2,   58,   37,   39,   43,    3],\n",
      "       [   2,   51,   37,   39,   43,    3],\n",
      "       [   2,   51,   38,   39,   43,    3],\n",
      "       [   2,   51,   39,   39,   43,    3],\n",
      "       [   2,   56, 1222,    3,    0,    0]], dtype=int64), array([[   2,   55,   37,   41,   38,    3],\n",
      "       [   2,   55,   38,   41,   38,    3],\n",
      "       [   2,   58,   37,   41,   38,    3],\n",
      "       [   2,   51,   37,   41,   38,    3],\n",
      "       [   2,   51,   38,   41,   38,    3],\n",
      "       [   2,   51,   39,   41,   38,    3],\n",
      "       [   2,   55,   37,   41,   39,    3],\n",
      "       [   2,   55,   38,   41,   39,    3],\n",
      "       [   2,   58,   37,   41,   39,    3],\n",
      "       [   2,   51,   37,   41,   39,    3],\n",
      "       [   2,   51,   38,   41,   39,    3],\n",
      "       [   2,   51,   39,   41,   39,    3],\n",
      "       [   2,   55,   37,   41,   40,    3],\n",
      "       [   2,   55,   38,   41,   40,    3],\n",
      "       [   2,   58,   37,   41,   40,    3],\n",
      "       [   2,   51,   37,   41,   40,    3],\n",
      "       [   2,   51,   38,   41,   40,    3],\n",
      "       [   2,   51,   39,   41,   40,    3],\n",
      "       [   2,   55,   37,   41,   41,    3],\n",
      "       [   2,   55,   38,   41,   41,    3],\n",
      "       [   2,   58,   37,   41,   41,    3],\n",
      "       [   2,   51,   37,   41,   41,    3],\n",
      "       [   2,   51,   38,   41,   41,    3],\n",
      "       [   2,   51,   39,   41,   41,    3],\n",
      "       [   2,   55,   37,   41,   42,    3],\n",
      "       [   2,   55,   38,   41,   42,    3],\n",
      "       [   2,   58,   37,   41,   42,    3],\n",
      "       [   2,   51,   37,   41,   42,    3],\n",
      "       [   2,   51,   38,   41,   42,    3],\n",
      "       [   2,   51,   39,   41,   42,    3],\n",
      "       [   2,   55,   37,   41,   43,    3],\n",
      "       [   2,   55,   38,   41,   43,    3],\n",
      "       [   2,   58,   37,   41,   43,    3],\n",
      "       [   2,   51,   37,   41,   43,    3],\n",
      "       [   2,   51,   38,   41,   43,    3],\n",
      "       [   2,   51,   39,   41,   43,    3],\n",
      "       [   2,   56, 1044,    3,    0,    0]], dtype=int64), array([[   2,   55,   37,   38,   38,    3],\n",
      "       [   2,   55,   38,   38,   38,    3],\n",
      "       [   2,   58,   37,   38,   38,    3],\n",
      "       [   2,   51,   37,   38,   38,    3],\n",
      "       [   2,   51,   38,   38,   38,    3],\n",
      "       [   2,   51,   39,   38,   38,    3],\n",
      "       [   2,   55,   37,   38,   39,    3],\n",
      "       [   2,   55,   38,   38,   39,    3],\n",
      "       [   2,   58,   37,   38,   39,    3],\n",
      "       [   2,   51,   37,   38,   39,    3],\n",
      "       [   2,   51,   38,   38,   39,    3],\n",
      "       [   2,   51,   39,   38,   39,    3],\n",
      "       [   2,   55,   37,   38,   40,    3],\n",
      "       [   2,   55,   38,   38,   40,    3],\n",
      "       [   2,   58,   37,   38,   40,    3],\n",
      "       [   2,   51,   37,   38,   40,    3],\n",
      "       [   2,   51,   38,   38,   40,    3],\n",
      "       [   2,   51,   39,   38,   40,    3],\n",
      "       [   2,   55,   37,   38,   41,    3],\n",
      "       [   2,   55,   38,   38,   41,    3],\n",
      "       [   2,   58,   37,   38,   41,    3],\n",
      "       [   2,   51,   37,   38,   41,    3],\n",
      "       [   2,   51,   38,   38,   41,    3],\n",
      "       [   2,   51,   39,   38,   41,    3],\n",
      "       [   2,   55,   37,   38,   42,    3],\n",
      "       [   2,   55,   38,   38,   42,    3],\n",
      "       [   2,   58,   37,   38,   42,    3],\n",
      "       [   2,   51,   37,   38,   42,    3],\n",
      "       [   2,   51,   38,   38,   42,    3],\n",
      "       [   2,   51,   39,   38,   42,    3],\n",
      "       [   2,   55,   37,   38,   43,    3],\n",
      "       [   2,   55,   38,   38,   43,    3],\n",
      "       [   2,   58,   37,   38,   43,    3],\n",
      "       [   2,   51,   37,   38,   43,    3],\n",
      "       [   2,   51,   38,   38,   43,    3],\n",
      "       [   2,   51,   39,   38,   43,    3],\n",
      "       [   2,   56, 1205,    3,    0,    0]], dtype=int64), array([[   2,   55,   37,   40,   38,    3],\n",
      "       [   2,   55,   38,   40,   38,    3],\n",
      "       [   2,   58,   37,   40,   38,    3],\n",
      "       [   2,   51,   37,   40,   38,    3],\n",
      "       [   2,   51,   38,   40,   38,    3],\n",
      "       [   2,   51,   39,   40,   38,    3],\n",
      "       [   2,   55,   37,   40,   39,    3],\n",
      "       [   2,   55,   38,   40,   39,    3],\n",
      "       [   2,   58,   37,   40,   39,    3],\n",
      "       [   2,   51,   37,   40,   39,    3],\n",
      "       [   2,   51,   38,   40,   39,    3],\n",
      "       [   2,   51,   39,   40,   39,    3],\n",
      "       [   2,   55,   37,   40,   40,    3],\n",
      "       [   2,   55,   38,   40,   40,    3],\n",
      "       [   2,   58,   37,   40,   40,    3],\n",
      "       [   2,   51,   37,   40,   40,    3],\n",
      "       [   2,   51,   38,   40,   40,    3],\n",
      "       [   2,   51,   39,   40,   40,    3],\n",
      "       [   2,   55,   37,   40,   41,    3],\n",
      "       [   2,   55,   38,   40,   41,    3],\n",
      "       [   2,   58,   37,   40,   41,    3],\n",
      "       [   2,   51,   37,   40,   41,    3],\n",
      "       [   2,   51,   38,   40,   41,    3],\n",
      "       [   2,   51,   39,   40,   41,    3],\n",
      "       [   2,   55,   37,   40,   42,    3],\n",
      "       [   2,   55,   38,   40,   42,    3],\n",
      "       [   2,   58,   37,   40,   42,    3],\n",
      "       [   2,   51,   37,   40,   42,    3],\n",
      "       [   2,   51,   38,   40,   42,    3],\n",
      "       [   2,   51,   39,   40,   42,    3],\n",
      "       [   2,   55,   37,   40,   43,    3],\n",
      "       [   2,   55,   38,   40,   43,    3],\n",
      "       [   2,   58,   37,   40,   43,    3],\n",
      "       [   2,   51,   37,   40,   43,    3],\n",
      "       [   2,   51,   38,   40,   43,    3],\n",
      "       [   2,   51,   39,   40,   43,    3],\n",
      "       [   2,   56, 1223,    3,    0,    0]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "def bad_make_batches2(ds):\n",
    "    return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .map(bad_tokenizer, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([gen_row(i+1) for i in range(5)])\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "bad_batches = bad_make_batches2(dataset)\n",
    "print(bad_batches)\n",
    "l = list(bad_batches.as_numpy_iterator())\n",
    "print(len(l))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69c84866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (37,), types: tf.string>\n",
      "5\n",
      "<PrefetchDataset shapes: ((None, None), (None, None)), types: (tf.int64, tf.int64)>\n",
      "3\n",
      "3\n",
      "[(array([[ 2, 55, 37, 40, 38,  3,  2, 55, 38, 40, 38,  3,  2, 58, 37, 40,\n",
      "        38,  3,  2, 51, 37, 40, 38,  3,  2, 51, 38, 40, 38,  3,  2, 51,\n",
      "        39, 40, 38,  3,  2, 55, 37, 40, 39,  3,  2, 55, 38, 40, 39,  3,\n",
      "         2, 58, 37, 40, 39,  3,  2, 51, 37, 40, 39,  3,  2, 51, 38, 40,\n",
      "        39,  3,  2, 51, 39, 40, 39,  3,  2, 55, 37, 40, 40,  3,  2, 55,\n",
      "        38, 40, 40,  3,  2, 58, 37, 40, 40,  3,  2, 51, 37, 40, 40,  3,\n",
      "         2, 51, 38, 40, 40,  3,  2, 51, 39, 40, 40,  3,  2, 55, 37, 40,\n",
      "        41,  3,  2, 55, 38, 40, 41,  3,  2, 58, 37, 40, 41,  3,  2, 51,\n",
      "        37, 40, 41,  3,  2, 51, 38, 40, 41,  3,  2, 51, 39, 40, 41,  3,\n",
      "         2, 55, 37, 40, 42,  3,  2, 55, 38, 40, 42,  3,  2, 58, 37, 40,\n",
      "        42,  3,  2, 51, 37, 40, 42,  3,  2, 51, 38, 40, 42,  3,  2, 51,\n",
      "        39, 40, 42,  3,  2, 55, 37, 40, 43,  3,  2, 55, 38, 40, 43,  3,\n",
      "         2, 58, 37, 40, 43,  3,  2, 51, 37, 40, 43,  3,  2, 51, 38, 40,\n",
      "        43,  3,  2, 51, 39, 40, 43,  3],\n",
      "       [ 2, 55, 37, 42, 38,  3,  2, 55, 38, 42, 38,  3,  2, 58, 37, 42,\n",
      "        38,  3,  2, 51, 37, 42, 38,  3,  2, 51, 38, 42, 38,  3,  2, 51,\n",
      "        39, 42, 38,  3,  2, 55, 37, 42, 39,  3,  2, 55, 38, 42, 39,  3,\n",
      "         2, 58, 37, 42, 39,  3,  2, 51, 37, 42, 39,  3,  2, 51, 38, 42,\n",
      "        39,  3,  2, 51, 39, 42, 39,  3,  2, 55, 37, 42, 40,  3,  2, 55,\n",
      "        38, 42, 40,  3,  2, 58, 37, 42, 40,  3,  2, 51, 37, 42, 40,  3,\n",
      "         2, 51, 38, 42, 40,  3,  2, 51, 39, 42, 40,  3,  2, 55, 37, 42,\n",
      "        41,  3,  2, 55, 38, 42, 41,  3,  2, 58, 37, 42, 41,  3,  2, 51,\n",
      "        37, 42, 41,  3,  2, 51, 38, 42, 41,  3,  2, 51, 39, 42, 41,  3,\n",
      "         2, 55, 37, 42, 42,  3,  2, 55, 38, 42, 42,  3,  2, 58, 37, 42,\n",
      "        42,  3,  2, 51, 37, 42, 42,  3,  2, 51, 38, 42, 42,  3,  2, 51,\n",
      "        39, 42, 42,  3,  2, 55, 37, 42, 43,  3,  2, 55, 38, 42, 43,  3,\n",
      "         2, 58, 37, 42, 43,  3,  2, 51, 37, 42, 43,  3,  2, 51, 38, 42,\n",
      "        43,  3,  2, 51, 39, 42, 43,  3]], dtype=int64), array([[   2,   56, 1223,    3,    0,    0],\n",
      "       [   2,   56, 1800,    3,    0,    0]], dtype=int64)), (array([[ 2, 55, 37, 41, 38,  3,  2, 55, 38, 41, 38,  3,  2, 58, 37, 41,\n",
      "        38,  3,  2, 51, 37, 41, 38,  3,  2, 51, 38, 41, 38,  3,  2, 51,\n",
      "        39, 41, 38,  3,  2, 55, 37, 41, 39,  3,  2, 55, 38, 41, 39,  3,\n",
      "         2, 58, 37, 41, 39,  3,  2, 51, 37, 41, 39,  3,  2, 51, 38, 41,\n",
      "        39,  3,  2, 51, 39, 41, 39,  3,  2, 55, 37, 41, 40,  3,  2, 55,\n",
      "        38, 41, 40,  3,  2, 58, 37, 41, 40,  3,  2, 51, 37, 41, 40,  3,\n",
      "         2, 51, 38, 41, 40,  3,  2, 51, 39, 41, 40,  3,  2, 55, 37, 41,\n",
      "        41,  3,  2, 55, 38, 41, 41,  3,  2, 58, 37, 41, 41,  3,  2, 51,\n",
      "        37, 41, 41,  3,  2, 51, 38, 41, 41,  3,  2, 51, 39, 41, 41,  3,\n",
      "         2, 55, 37, 41, 42,  3,  2, 55, 38, 41, 42,  3,  2, 58, 37, 41,\n",
      "        42,  3,  2, 51, 37, 41, 42,  3,  2, 51, 38, 41, 42,  3,  2, 51,\n",
      "        39, 41, 42,  3,  2, 55, 37, 41, 43,  3,  2, 55, 38, 41, 43,  3,\n",
      "         2, 58, 37, 41, 43,  3,  2, 51, 37, 41, 43,  3,  2, 51, 38, 41,\n",
      "        43,  3,  2, 51, 39, 41, 43,  3],\n",
      "       [ 2, 55, 37, 39, 38,  3,  2, 55, 38, 39, 38,  3,  2, 58, 37, 39,\n",
      "        38,  3,  2, 51, 37, 39, 38,  3,  2, 51, 38, 39, 38,  3,  2, 51,\n",
      "        39, 39, 38,  3,  2, 55, 37, 39, 39,  3,  2, 55, 38, 39, 39,  3,\n",
      "         2, 58, 37, 39, 39,  3,  2, 51, 37, 39, 39,  3,  2, 51, 38, 39,\n",
      "        39,  3,  2, 51, 39, 39, 39,  3,  2, 55, 37, 39, 40,  3,  2, 55,\n",
      "        38, 39, 40,  3,  2, 58, 37, 39, 40,  3,  2, 51, 37, 39, 40,  3,\n",
      "         2, 51, 38, 39, 40,  3,  2, 51, 39, 39, 40,  3,  2, 55, 37, 39,\n",
      "        41,  3,  2, 55, 38, 39, 41,  3,  2, 58, 37, 39, 41,  3,  2, 51,\n",
      "        37, 39, 41,  3,  2, 51, 38, 39, 41,  3,  2, 51, 39, 39, 41,  3,\n",
      "         2, 55, 37, 39, 42,  3,  2, 55, 38, 39, 42,  3,  2, 58, 37, 39,\n",
      "        42,  3,  2, 51, 37, 39, 42,  3,  2, 51, 38, 39, 42,  3,  2, 51,\n",
      "        39, 39, 42,  3,  2, 55, 37, 39, 43,  3,  2, 55, 38, 39, 43,  3,\n",
      "         2, 58, 37, 39, 43,  3,  2, 51, 37, 39, 43,  3,  2, 51, 38, 39,\n",
      "        43,  3,  2, 51, 39, 39, 43,  3]], dtype=int64), array([[   2,   56, 1044,    3,    0,    0],\n",
      "       [   2,   56, 1222,    3,    0,    0]], dtype=int64)), (array([[ 2, 55, 37, 38, 38,  3,  2, 55, 38, 38, 38,  3,  2, 58, 37, 38,\n",
      "        38,  3,  2, 51, 37, 38, 38,  3,  2, 51, 38, 38, 38,  3,  2, 51,\n",
      "        39, 38, 38,  3,  2, 55, 37, 38, 39,  3,  2, 55, 38, 38, 39,  3,\n",
      "         2, 58, 37, 38, 39,  3,  2, 51, 37, 38, 39,  3,  2, 51, 38, 38,\n",
      "        39,  3,  2, 51, 39, 38, 39,  3,  2, 55, 37, 38, 40,  3,  2, 55,\n",
      "        38, 38, 40,  3,  2, 58, 37, 38, 40,  3,  2, 51, 37, 38, 40,  3,\n",
      "         2, 51, 38, 38, 40,  3,  2, 51, 39, 38, 40,  3,  2, 55, 37, 38,\n",
      "        41,  3,  2, 55, 38, 38, 41,  3,  2, 58, 37, 38, 41,  3,  2, 51,\n",
      "        37, 38, 41,  3,  2, 51, 38, 38, 41,  3,  2, 51, 39, 38, 41,  3,\n",
      "         2, 55, 37, 38, 42,  3,  2, 55, 38, 38, 42,  3,  2, 58, 37, 38,\n",
      "        42,  3,  2, 51, 37, 38, 42,  3,  2, 51, 38, 38, 42,  3,  2, 51,\n",
      "        39, 38, 42,  3,  2, 55, 37, 38, 43,  3,  2, 55, 38, 38, 43,  3,\n",
      "         2, 58, 37, 38, 43,  3,  2, 51, 37, 38, 43,  3,  2, 51, 38, 38,\n",
      "        43,  3,  2, 51, 39, 38, 43,  3]], dtype=int64), array([[   2,   56, 1205,    3,    0,    0]], dtype=int64))]\n"
     ]
    }
   ],
   "source": [
    "def tokenizator(l):\n",
    "    t = tokenizers.en.tokenize(l).to_tensor()\n",
    "    return (tf.reshape(t[:-1], [-1]), t[-1])\n",
    "\n",
    "def bad_make_batches3(ds):\n",
    "    return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .map(tokenizator, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .batch(2)\n",
    "      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "li = [gen_row(i+1) for i in range(5)]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(li)\n",
    "del li\n",
    "#El primer parámetro determina los n primeros elementos para ir seleccionando las posiciones\n",
    "print(dataset)\n",
    "print(dataset.cardinality().numpy())\n",
    "bad_batches = bad_make_batches3(dataset)\n",
    "print(bad_batches)\n",
    "l = list(bad_batches.as_numpy_iterator())\n",
    "print(bad_batches.cardinality().numpy())\n",
    "print(len(l))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2578d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(bad_batches, './save_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fdf7b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_LoadDataset shapes: ((None, None), (None, None)), types: (tf.int64, tf.int64)>\n",
      "3\n",
      "[(array([[ 2, 55, 37, 41, 38,  3,  2, 55, 38, 41, 38,  3,  2, 58, 37, 41,\n",
      "        38,  3,  2, 51, 37, 41, 38,  3,  2, 51, 38, 41, 38,  3,  2, 51,\n",
      "        39, 41, 38,  3,  2, 55, 37, 41, 39,  3,  2, 55, 38, 41, 39,  3,\n",
      "         2, 58, 37, 41, 39,  3,  2, 51, 37, 41, 39,  3,  2, 51, 38, 41,\n",
      "        39,  3,  2, 51, 39, 41, 39,  3,  2, 55, 37, 41, 40,  3,  2, 55,\n",
      "        38, 41, 40,  3,  2, 58, 37, 41, 40,  3,  2, 51, 37, 41, 40,  3,\n",
      "         2, 51, 38, 41, 40,  3,  2, 51, 39, 41, 40,  3,  2, 55, 37, 41,\n",
      "        41,  3,  2, 55, 38, 41, 41,  3,  2, 58, 37, 41, 41,  3,  2, 51,\n",
      "        37, 41, 41,  3,  2, 51, 38, 41, 41,  3,  2, 51, 39, 41, 41,  3,\n",
      "         2, 55, 37, 41, 42,  3,  2, 55, 38, 41, 42,  3,  2, 58, 37, 41,\n",
      "        42,  3,  2, 51, 37, 41, 42,  3,  2, 51, 38, 41, 42,  3,  2, 51,\n",
      "        39, 41, 42,  3,  2, 55, 37, 41, 43,  3,  2, 55, 38, 41, 43,  3,\n",
      "         2, 58, 37, 41, 43,  3,  2, 51, 37, 41, 43,  3,  2, 51, 38, 41,\n",
      "        43,  3,  2, 51, 39, 41, 43,  3],\n",
      "       [ 2, 55, 37, 40, 38,  3,  2, 55, 38, 40, 38,  3,  2, 58, 37, 40,\n",
      "        38,  3,  2, 51, 37, 40, 38,  3,  2, 51, 38, 40, 38,  3,  2, 51,\n",
      "        39, 40, 38,  3,  2, 55, 37, 40, 39,  3,  2, 55, 38, 40, 39,  3,\n",
      "         2, 58, 37, 40, 39,  3,  2, 51, 37, 40, 39,  3,  2, 51, 38, 40,\n",
      "        39,  3,  2, 51, 39, 40, 39,  3,  2, 55, 37, 40, 40,  3,  2, 55,\n",
      "        38, 40, 40,  3,  2, 58, 37, 40, 40,  3,  2, 51, 37, 40, 40,  3,\n",
      "         2, 51, 38, 40, 40,  3,  2, 51, 39, 40, 40,  3,  2, 55, 37, 40,\n",
      "        41,  3,  2, 55, 38, 40, 41,  3,  2, 58, 37, 40, 41,  3,  2, 51,\n",
      "        37, 40, 41,  3,  2, 51, 38, 40, 41,  3,  2, 51, 39, 40, 41,  3,\n",
      "         2, 55, 37, 40, 42,  3,  2, 55, 38, 40, 42,  3,  2, 58, 37, 40,\n",
      "        42,  3,  2, 51, 37, 40, 42,  3,  2, 51, 38, 40, 42,  3,  2, 51,\n",
      "        39, 40, 42,  3,  2, 55, 37, 40, 43,  3,  2, 55, 38, 40, 43,  3,\n",
      "         2, 58, 37, 40, 43,  3,  2, 51, 37, 40, 43,  3,  2, 51, 38, 40,\n",
      "        43,  3,  2, 51, 39, 40, 43,  3]], dtype=int64), array([[   2,   56, 1044,    3,    0,    0],\n",
      "       [   2,   56, 1223,    3,    0,    0]], dtype=int64)), (array([[ 2, 55, 37, 39, 38,  3,  2, 55, 38, 39, 38,  3,  2, 58, 37, 39,\n",
      "        38,  3,  2, 51, 37, 39, 38,  3,  2, 51, 38, 39, 38,  3,  2, 51,\n",
      "        39, 39, 38,  3,  2, 55, 37, 39, 39,  3,  2, 55, 38, 39, 39,  3,\n",
      "         2, 58, 37, 39, 39,  3,  2, 51, 37, 39, 39,  3,  2, 51, 38, 39,\n",
      "        39,  3,  2, 51, 39, 39, 39,  3,  2, 55, 37, 39, 40,  3,  2, 55,\n",
      "        38, 39, 40,  3,  2, 58, 37, 39, 40,  3,  2, 51, 37, 39, 40,  3,\n",
      "         2, 51, 38, 39, 40,  3,  2, 51, 39, 39, 40,  3,  2, 55, 37, 39,\n",
      "        41,  3,  2, 55, 38, 39, 41,  3,  2, 58, 37, 39, 41,  3,  2, 51,\n",
      "        37, 39, 41,  3,  2, 51, 38, 39, 41,  3,  2, 51, 39, 39, 41,  3,\n",
      "         2, 55, 37, 39, 42,  3,  2, 55, 38, 39, 42,  3,  2, 58, 37, 39,\n",
      "        42,  3,  2, 51, 37, 39, 42,  3,  2, 51, 38, 39, 42,  3,  2, 51,\n",
      "        39, 39, 42,  3,  2, 55, 37, 39, 43,  3,  2, 55, 38, 39, 43,  3,\n",
      "         2, 58, 37, 39, 43,  3,  2, 51, 37, 39, 43,  3,  2, 51, 38, 39,\n",
      "        43,  3,  2, 51, 39, 39, 43,  3],\n",
      "       [ 2, 55, 37, 38, 38,  3,  2, 55, 38, 38, 38,  3,  2, 58, 37, 38,\n",
      "        38,  3,  2, 51, 37, 38, 38,  3,  2, 51, 38, 38, 38,  3,  2, 51,\n",
      "        39, 38, 38,  3,  2, 55, 37, 38, 39,  3,  2, 55, 38, 38, 39,  3,\n",
      "         2, 58, 37, 38, 39,  3,  2, 51, 37, 38, 39,  3,  2, 51, 38, 38,\n",
      "        39,  3,  2, 51, 39, 38, 39,  3,  2, 55, 37, 38, 40,  3,  2, 55,\n",
      "        38, 38, 40,  3,  2, 58, 37, 38, 40,  3,  2, 51, 37, 38, 40,  3,\n",
      "         2, 51, 38, 38, 40,  3,  2, 51, 39, 38, 40,  3,  2, 55, 37, 38,\n",
      "        41,  3,  2, 55, 38, 38, 41,  3,  2, 58, 37, 38, 41,  3,  2, 51,\n",
      "        37, 38, 41,  3,  2, 51, 38, 38, 41,  3,  2, 51, 39, 38, 41,  3,\n",
      "         2, 55, 37, 38, 42,  3,  2, 55, 38, 38, 42,  3,  2, 58, 37, 38,\n",
      "        42,  3,  2, 51, 37, 38, 42,  3,  2, 51, 38, 38, 42,  3,  2, 51,\n",
      "        39, 38, 42,  3,  2, 55, 37, 38, 43,  3,  2, 55, 38, 38, 43,  3,\n",
      "         2, 58, 37, 38, 43,  3,  2, 51, 37, 38, 43,  3,  2, 51, 38, 38,\n",
      "        43,  3,  2, 51, 39, 38, 43,  3]], dtype=int64), array([[   2,   56, 1222,    3,    0,    0],\n",
      "       [   2,   56, 1205,    3,    0,    0]], dtype=int64)), (array([[ 2, 55, 37, 42, 38,  3,  2, 55, 38, 42, 38,  3,  2, 58, 37, 42,\n",
      "        38,  3,  2, 51, 37, 42, 38,  3,  2, 51, 38, 42, 38,  3,  2, 51,\n",
      "        39, 42, 38,  3,  2, 55, 37, 42, 39,  3,  2, 55, 38, 42, 39,  3,\n",
      "         2, 58, 37, 42, 39,  3,  2, 51, 37, 42, 39,  3,  2, 51, 38, 42,\n",
      "        39,  3,  2, 51, 39, 42, 39,  3,  2, 55, 37, 42, 40,  3,  2, 55,\n",
      "        38, 42, 40,  3,  2, 58, 37, 42, 40,  3,  2, 51, 37, 42, 40,  3,\n",
      "         2, 51, 38, 42, 40,  3,  2, 51, 39, 42, 40,  3,  2, 55, 37, 42,\n",
      "        41,  3,  2, 55, 38, 42, 41,  3,  2, 58, 37, 42, 41,  3,  2, 51,\n",
      "        37, 42, 41,  3,  2, 51, 38, 42, 41,  3,  2, 51, 39, 42, 41,  3,\n",
      "         2, 55, 37, 42, 42,  3,  2, 55, 38, 42, 42,  3,  2, 58, 37, 42,\n",
      "        42,  3,  2, 51, 37, 42, 42,  3,  2, 51, 38, 42, 42,  3,  2, 51,\n",
      "        39, 42, 42,  3,  2, 55, 37, 42, 43,  3,  2, 55, 38, 42, 43,  3,\n",
      "         2, 58, 37, 42, 43,  3,  2, 51, 37, 42, 43,  3,  2, 51, 38, 42,\n",
      "        43,  3,  2, 51, 39, 42, 43,  3]], dtype=int64), array([[   2,   56, 1800,    3,    0,    0]], dtype=int64))]\n"
     ]
    }
   ],
   "source": [
    "bad_batches = tf.data.experimental.load('./save_test/')\n",
    "print(bad_batches)\n",
    "l = list(bad_batches.as_numpy_iterator())\n",
    "print(len(l))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9623cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "list(train_examples.take(3).as_numpy_iterator())\n",
    "print(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf1ed15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17262\n",
      "[(array([b'e est\\xc3\\xa3o a ser confeccionados das formas mais deliciosas .',\n",
      "       b\"`` ora , este \\xc3\\xa9 o mesmo adam smith que , 17 anos mais tarde , escreveria um pequeno livro chamado `` '' a riqueza das na\\xc3\\xa7\\xc3\\xb5es '' '' \\xe2\\x80\\x94 o documento fundador da economia . ''\",\n",
      "       b'nessa altura , foi apenas a fa\\xc3\\xadsca de uma ideia .'],\n",
      "      dtype=object), array([b\"and they 're being made in the most wonderful ways .\",\n",
      "       b\"`` now this is the same adam smith who , 17 years later , would write a little book called `` '' the wealth of nations '' '' \\xe2\\x80\\x94 the founding document of economics . ''\",\n",
      "       b'it was at that point , just the spark of an idea .'],\n",
      "      dtype=object)), (array([b'ent\\xc3\\xa3o , o planeamento de resposta no s\\xc3\\xa9culo vinte e um \\xc3\\xa9 poss\\xc3\\xadvel e tamb\\xc3\\xa9m \\xc3\\xa9 essencial .',\n",
      "       b'um dos an\\xc3\\xbancios da ind\\xc3\\xbastria do carv\\xc3\\xa3o na \\xc3\\xa9poca do natal foi o seguinte .',\n",
      "       b'us\\xc3\\xa1mo-lo na capela de loyola e n\\xc3\\xa3o funcionou .'],\n",
      "      dtype=object), array([b'so , response planning in the twenty-first century is both possible and is essential .',\n",
      "       b\"one of the coal industry 's ads around christmas was this one .\",\n",
      "       b\"we used it at loyola on the chapel , and it did n't work .\"],\n",
      "      dtype=object))]\n"
     ]
    }
   ],
   "source": [
    "train_batches = first_make_batch(train_examples)\n",
    "l = list(train_batches.as_numpy_iterator())\n",
    "print(len(l))\n",
    "print(l[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "003182fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n",
      "<PrefetchDataset shapes: ((None, None), (None, None)), types: (tf.int64, tf.int64)>\n",
      "810\n",
      "[(array([[  2,  39,  39, ...,   0,   0,   0],\n",
      "       [  2,  88,  44, ...,   0,   0,   0],\n",
      "       [  2,  88,  54, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  2, 103, 744, ...,   0,   0,   0],\n",
      "       [  2, 108, 583, ...,   0,   0,   0],\n",
      "       [  2, 100, 142, ...,   0,   0,   0]], dtype=int64), array([[  2, 117,  79, ...,   0,   0,   0],\n",
      "       [  2,  76,   9, ...,   0,   0,   0],\n",
      "       [  2,  45,  91, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  2, 110,  13, ...,   0,   0,   0],\n",
      "       [  2,  82,  81, ...,   0,   0,   0],\n",
      "       [  2, 482,  99, ...,   0,   0,   0]], dtype=int64)), (array([[   2,  120,   85, ...,    0,    0,    0],\n",
      "       [   2, 5131,  319, ...,    0,    0,    0],\n",
      "       [   2,   85,  187, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2,   39,   39, ...,    0,    0,    0],\n",
      "       [   2,  122,   54, ...,    0,    0,    0],\n",
      "       [   2, 2807,   28, ...,    0,    0,    0]], dtype=int64), array([[   2,   96,    9, ...,    0,    0,    0],\n",
      "       [   2,  229,   73, ...,    0,    0,    0],\n",
      "       [   2,   72,  146, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2,   93,   81, ...,    0,    0,    0],\n",
      "       [   2,   82,   90, ...,    0,    0,    0],\n",
      "       [   2, 2505,   27, ...,    0,    0,    0]], dtype=int64))]\n"
     ]
    }
   ],
   "source": [
    "print(train_examples)\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)\n",
    "print(train_batches)\n",
    "l = list(train_batches.as_numpy_iterator())\n",
    "print(len(l))\n",
    "print(l[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779112b",
   "metadata": {},
   "source": [
    "# Position embedding\n",
    "\n",
    "Para que el transformer tenga en cuenta la posición de cada palabra, es necesario calcular los [vectores de codificación posicional](https://www.youtube.com/watch?v=dichIcUZfOw). Implementemos su cálculo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87abe204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de8edb",
   "metadata": {},
   "source": [
    "# Masking\n",
    "Enmascaramos todos los tokens de relleno con la primera función (se obtiene un 1 en donde se encuentren y un 0 en caso contrario). La segunda genera una máscara de predicción, es decir, indica que para predecir el segundo token solo debe usarse el primero. Para ello produce una matrix triangular superior con 0 en la diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cb1f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    #tf.math.equal(seq, 0) genera una matriz cuyo valor es True en aquellas posiciones en que en la matriz seq\n",
    "    #sea 0\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    #Produce una matriz triangular superior con la diagonal nula\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0a0e3",
   "metadata": {},
   "source": [
    "# Producto escalar de atención\n",
    "Para implementar la arquitectura transformer es necesario utilizar la fórmula del [producto escalar de atención](https://www.youtube.com/watch?v=mMa2PmYJlCo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ae7272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        #La idea de multiplicar la máscara por -1e9 (infinito negativo) es luego al pasarlo por la función\n",
    "        #softmax se obtenga el valor 0 en estas posiciones del vector\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab9466",
   "metadata": {},
   "source": [
    "# Multi-head attention\n",
    "\n",
    "Implementamos el modelo de atención:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd1aa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads = 8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        if d_model % self.num_heads != 0:\n",
    "            raise ValueError(\"MutilHeadAttention: dimension of the model must be a multiple of the number of heads.\")\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        # El -1 permite ajustar esa dimensión en función del nº de elementos\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471c10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.9203881  0.86875725 0.17757976 ... 0.74866164 0.17869365 0.8598305 ]\n",
      "  [0.89917386 0.02581131 0.04312754 ... 0.8769504  0.85391784 0.40402937]\n",
      "  [0.22640431 0.12835097 0.8253164  ... 0.35835552 0.01738381 0.7351848 ]\n",
      "  ...\n",
      "  [0.39145565 0.8043041  0.8042283  ... 0.3424486  0.8928033  0.500561  ]\n",
      "  [0.5837436  0.60191214 0.638535   ... 0.03918517 0.04287899 0.8385978 ]\n",
      "  [0.48036265 0.7935188  0.6060002  ... 0.11286104 0.773556   0.7830714 ]]], shape=(1, 60, 512), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "print(y)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c2641",
   "metadata": {},
   "source": [
    "# Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b28abbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe9d01",
   "metadata": {},
   "source": [
    "# Encoded Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2bceb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        #dff = dimension feed forward, dimensión de la capa interna\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb447058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d41ae",
   "metadata": {},
   "source": [
    "# Decoded Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45146bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b423ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d2270",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2d20d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                   maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9295836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fdd94",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f281d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3fa85a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=False,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e36cb",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72ffac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # Keras models prefer if you pass all your inputs in the first argument\n",
    "        inp, tar = inputs\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights\n",
    "\n",
    "    def create_masks(self, inp, tar):\n",
    "        # Encoder padding mask\n",
    "        enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 2nd attention block in the decoder.\n",
    "        # This padding mask is used to mask the encoder outputs.\n",
    "        dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 1st attention block in the decoder.\n",
    "        # It is used to pad and mask future tokens in the input received by\n",
    "        # the decoder.\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "        dec_target_padding_mask = create_padding_mask(tar)\n",
    "        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ae5bc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 36, 8000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000,\n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((256, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((256, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer([temp_input, temp_target], training=False)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201be3ee",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eae62eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4 #6\n",
    "d_model = 128 #512\n",
    "dff = 512 #2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8821671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d8ed196",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f3b23c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebe362",
   "metadata": {},
   "source": [
    "# Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1c9e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5891014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc772d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667e2221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_LoadDataset shapes: (3,), types: tf.string>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dss = tf.data.experimental.load(\"dss\")\n",
    "dss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
