\chapter{Conclusiones y Trabajo Futuro}
\label{cap:conclusiones}

\chapterquote{Difícil de ver es. Siempre en movimiento el futuro está}{Yoda - Star Wars: Episodio III - La venganza de los Sith (2005)}

Tras el desarrollo de este trabajo, en este capítulo se presentan las conclusiones que pueden extraerse de este estudio (se explican en la sección \ref{s:concl}). justo después, las posibles opciones para la continuación de este trabajo quedan expuestas en la sección \ref{s:fut}, con el fin de continuar con el estudio de la generación de lenguaje natural a partir de representaciones semánticas.

\section{Conclusiones}\label{s:concl}

Hoy en día, el correo electrónico es un sistema de comunicación que se utiliza tanto en el ámbito profesional como en el personal. A través de él se establecen conversaciones sobre el trabajo, los estudios, relaciones íntimas, etcétera. Sin embargo, el gran número de e-mails que se reciben y envían cada día comienza a obligar a sus usuarios a dedicar una notable cantidad de tiempo a atender su cuenta y pensar cuál es la mejor forma de redactarlo para transmitir la idea que se tiene en mente. Pero, ¿y si se pudiera escribir de forma automática con tan solo introducir como entrada dicha idea? Este problema puede ser resuelto mediante el uso de técnicas de generación de lenguaje natural, que es un campo de la inteligencia artificial que se enfrenta al reto de producir textos imitando la forma en que los humanos se comunican entre sí. Dentro de esta rama, destacan dos tipos de arquitecturas: los modelos realizer y los modelos transformer. La primera aproximación consiste en un pipeline de tareas que, poco a poco, construyen el texto de salida; mientras que la segunda hace uso de los modelos de atención y las arquitecturas codificador-decodificador de deep learning. En este trabajo se trata de evaluar la viabilidad de implementar cada una de ellas para enfrentarse al problema de redacción automática de correos electrónicos, desarrollar la solución y valorar los resultados obtenidos.

Para representar esa idea que el usuario posee, se hace uso de los llamados Information Items, entidades que almacenan la mínima información semántica. Este elemento proviene de la rama del resumen automático de textos. Los Information Items serán la entrada del sistema desarrollado representando ese concepto que posee el usuario acerca de lo que quiere redactar el correo electrónico. Concretamente se implementan mediante tuplas sujeto-verbo-objeto. Sin embargo, como se ha mostrado en el trabajo, esta definición no funciona adecuadamente en ninguna de las dos arquitecturas, ya que obliga al sistema de generación de lenguaje natural a producir construcciones lingüísticas con elementos semánticos on transmitidos por el usuario y que no puede obtener de otra manera.

\section{Trabajo futuro}\label{s:fut}
En vista de los resultados obtenidos, la principal vía de trabajo futuro es el estudio de la redacción automática de correos electrónicos utilizando otras implementaciones más complejas de los Information Items. La clave reside en que almacenen la suficiente información como para ser capaces de generar por completo el mensaje, pero no excesiva como para que el usuario tenga que redactar prácticamente todo el mensaje. No obstante, no se descarta la posibilidad de que quizás, con un mayor conjunto de entrenamiento, la propuesta desarrollada a lo largo de este trabajo obtenga resultados satisfactorios. Por esa razón, otra opción para continuar el trabajo desarrollado es la reutilización de los módulos implementados (que pueden encontrarse en el repositorio correspondiente\footnote{\url{https://github.com/carlosmmorera/NLG-AI-Master-Thesis}}) y entrenarlos con un corpus mayor que permite exprimir la utilidad de los InIts.