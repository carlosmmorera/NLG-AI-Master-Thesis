\section{Implementación de una arquitectura realizer}\label{s:realizer}

El planteamiento inicial de este estudio era el de desarrollar una arquitectura realizer que fuera capaz de redactar correos electrónicos de manera automática. Como se explicó detalladamente en la sección \ref{sss:realizer}, el primer problema que surge ante esta propuesta son las estructuras de datos ad hoc generadas en función del dominio del que se quiere producir los textos de lenguaje natural. Esto resulta un inconveniente debido a que, a diferencia de aplicaciones con un dominio definido como pueden ser aquellas cuyo propósito es el de generar informes meteorológicos, la redacción automática de correos electrónicos resulta extremadamente difícil de enmarcar dentro de uno o varios dominios específicos. Además, el corpus que se ha elegido para entrenar el modelo, no se restringe a un tipo de temática de e-mails, sino que pueden encontrarse mensajes que versan sobre una gran variedad de temáticas. Esto complica más la implementación porque, aunque se limitara a un número razonable de asuntos y este hecho no fuera desvelado, el modelo podría ser capaz de aprender el lenguaje específico y las características lingüísticas inherentes a los dominios (por supuesto con mayor dificultad que si se fuera consciente de esta ventaja). Sin embargo, al no contar con esta facilidad, no existen entidades concretas o propiedades comunes más allá de las que posee el lenguaje general.

Si se estudia en detalle la arquitectura realizer, se observa que el mayor problema de restricción de dominio se encuentra en la fase de determinación del contenido. Por supuesto que en el resto de fases también está presente en mayor o menor medida, por ejemplo en la estructuración del documento, pero no posee tanta dependencia como esta primera tarea localizada en el pipeline de las arquitecturas de generación de lenguaje natural. La razón es que resulta sumamente complicado conceptualizar en una estructura de datos concreta, cualquier posible intención que se pueda tener a la hora de transmitir cualquier información. Aún así, la solución traída desde el ámbito del resumen abstractivo de textos, en la que dichas intenciones se materializan en tuplas sujeto-verbo-objeto, solucionaba en gran medida la dificultad del paso de determinación de contenido. Es decir, esta fase se resolvía mediante la generación de Information Items que indican los temas que se desean tratar a lo largo de todo el correo electrónico. De hecho, la gran ventaja de llevar a cabo esta aproximación es que, no solo abordaba el problema de determinación del contenido que, en principio, parecía insalvable, sino que también ofrecía una solución para generar la entrada para el entrenamiento del sistema. Dicho de otro modo, el corpus elegido no proporciona más que los correos electrónicos, que en teoría son la salida final del sistema de generación de lenguaje natural, por lo que no se cuenta con una entrada. Con la solución de las tuplas sujeto-verbo-objeto, es posible conseguir una supuesta entrada desde la que podrían haberse redactado los mensajes. Esto da paso a la utilización de técnicas de aprendizaje supervisado y evita tener que producir una entrada escrita a mano. En resumidas cuentas, con los Information Items ``matábamos dos pájaros de un tiro'': se conseguía un método de generación automática de una entrada para los correos electrónicos ya generados y se solventaba el problema de no ser capaces de concretar el dominio de los e-mails del corpus de cara a diseñar estructuras de datos ad hoc necesarias para implementar la fase de determinación del contenido. Sin embargo, los Information Items introducen un problema sumamente complicado de abordar. Al tratarse de estructuras genéricas que pueden versar sobre cualquier temática, esto impide que puedan usarse técnicas que añadan algún tipo de información adicional en la generación del texto. El origen de este gran escollo es que las fases subsiguientes a la determinación de contenido son altamente dependientes de la salida de esta última. Cuando el dominio es concreto se puede razonar sobre el contenido (con técnicas como las ontologías) o contar con entidades preestablecidas para añadir información extra al texto producido, mientras que al no poder enmarcarse dentro de uno o varios dominios, actualmente no existe la forma de razonar sobre conocimiento general. En consecuencia, el sistema de generación de lenguaje natural se limitaría a recibir las tuplas sujeto-verbo-objeto y construir estructuras lingüísticas que incluyeran única y exclusivamente la información semántica que transmiten los InIts en cuestión. Es decir, simplemente se podrían producir, a lo sumo, tantas oraciones como Information Items se recibiera y la única tarea sería la de generar las escasas estructuras sintácticas que faltaran, así como ajustar algunas categorías morfológicas como el tiempo de los verbos y el género y número de las palabras. Esta técnica de Information Items solo ha sido empleada en los sistemas de resumen automático de textos, precisamente porque impide que en el resto de fases se pueda añadir información adicional más allá de estructuras sintácticas necesarias para la correcta construcción de las oraciones.

Ante este panorama en que las fases subsiguientes a la determinación de contenido poseen una dependencia excesivamente alta cuando se utilizan los Information Items, se descartó la posibilidad de desarrollar este sistema siguiendo el esquema de arquitectura realizer y se optó por generar la aplicación siguiendo el modelo transformer.